{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2545ddb",
   "metadata": {},
   "source": [
    "# Parse the Price Checklist\n",
    "\n",
    "PDFs are evil. They're all pretty when you print them on the screen or paper but trying to parse them is an unmitigated nightmare. This is my attempt at parsing this one PDF: Price's *Chewing Lice with Host Associations*.\n",
    "\n",
    "The first trick to parsing PDFs is to get the output into a form that gives you a fighting chance to parse the output. I work from Linux so that limits what I have but, fortunately, there are some excellent tools available here: Poppler utils (poppler-utils). I'll be using this to convert the PDF into HTML.\n",
    "\n",
    "The next trick is to use a library to parse the HTML. Parsing HTML with regular expression is sometimes doable but it is really the wrong tool for this job. I use Beautiful Soup 4 for this, but there are other excellent choices. lxml is a backing library for Beautiful Soup.\n",
    "\n",
    "Side note: I prefer to use virtual environments, but that's just a personal preference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fb30ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install beautifulsoup4 lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ccf9fd",
   "metadata": {},
   "source": [
    "## Convert the PDF to HTML\n",
    "\n",
    "I'm using Poppler's pdftohtml utility for the conversion. The switches are:\n",
    "1. `-c` to create a \"complex HTML\" That will keep white spaces in the document. White space in this document has meaning and we will want to use it for parsing.\n",
    "1. `-q` keeps the utility from printing a lot of messages.\n",
    "\n",
    "[1] It will produce a bunch of \"png\" files which are background images for the pages. It also produces an \"outline\" which is the list of pages and links to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fba2be28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pdftohtml -c -q data/Price_louse.pdf data/Price_louse.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d3b5f6",
   "metadata": {},
   "source": [
    "## Examine the output\n",
    "\n",
    "Note: The output HTML (`Price_louse.pdf-<page_no>-.html`) looks better in Chromium than in Firefox.\n",
    "\n",
    "What the `-c` option for the conversion did was wrap all text in `<p>` tags with the class as a font reference. Importantly, the output contains absolute positioning in the style attributes. We can use this to prepare the text for parsing. So, open up the debug window in the browser (control-shift-I in Firefox) or a text editor to look at the output.\n",
    "\n",
    "There will be some HTML entities in the output like `&#160;` = `&nbsp;` which is a non-breaking space. We will clean this up later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5f9397",
   "metadata": {},
   "source": [
    "## And now the hunt begins\n",
    "\n",
    "- In this document page one is formatted differently, so we'll treat it differently. Every other page seems to be formatted alike.\n",
    "- Page classes start at zero and the first class is for the page footer/header so they should be pretty easy to strip.\n",
    "- We can use the style attribute's \"top\" to find lines and we can use the \"left\" and a cutoff value to find columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6896ba",
   "metadata": {},
   "source": [
    "## Start by reading the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a7c333d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0df4f7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = re.VERBOSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2f3cec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path('.') / 'data'\n",
    "PDF = DATA_DIR / 'Price_louse.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "457ba8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cdc6d3",
   "metadata": {},
   "source": [
    "## Create a dictionary of pages\n",
    "\n",
    "Each item will itself be a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9882a1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAGES = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbacfca2",
   "metadata": {},
   "source": [
    "## Build the initial page data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "835438e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for page in DATA_DIR.glob('Price_louse.pdf-*.html'):\n",
    "    match = re.search(r'Price_louse.pdf-(\\d+).html', str(page))\n",
    "\n",
    "    if not match:\n",
    "        continue\n",
    "\n",
    "    page_no = int(match.group(1))\n",
    "\n",
    "    with open(page) as in_file:\n",
    "        doc = in_file.read()\n",
    "\n",
    "    soup = BeautifulSoup(doc, features='lxml')\n",
    "\n",
    "    img = soup.img\n",
    "\n",
    "    PAGES[page_no] = {\n",
    "        'page': soup,\n",
    "        'width': int(img['width']),\n",
    "        'height': int(img['height']),\n",
    "    }\n",
    "\n",
    "len(PAGES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8c5165",
   "metadata": {},
   "source": [
    "## Remove unneeded tags from the pages\n",
    "\n",
    "We're going to wind up with a set of text fragments for each page. Each fragment will be wrapped in a `<p>` tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24203a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "for page_no, page in PAGES.items():\n",
    "    paras = page['page'].find_all('p')\n",
    "    removes = ['ft00', 'ft01', 'ft02'] if page_no == 1 else ['ft00']\n",
    "    paras = [p for p in paras if p['class'][0] not in removes]\n",
    "    page['paras'] = paras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9726a52d",
   "metadata": {},
   "source": [
    "## Sort the text fragments by column, top, left\n",
    "\n",
    "We're using the midpoint of the width of the page to determine what column the text belongs to.\n",
    "\n",
    "This should put all of the text in each page in order, provided we did the column separation correctly.\n",
    "\n",
    "While we're at it we remove the style and class attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6da28d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "for page_no, page in PAGES.items():\n",
    "    page['ordered'] = []\n",
    "\n",
    "    midpoint = page['width'] // 2\n",
    "\n",
    "    for p in page['paras']:\n",
    "        top = int(re.search(r'top:(\\d+)px', p['style']).group(1))\n",
    "        left = int(re.search(r'left:(\\d+)px', p['style']).group(1))\n",
    "\n",
    "        col = 0 if left < midpoint else 1\n",
    "\n",
    "        del p['class']\n",
    "        del p['style']\n",
    "\n",
    "        page['ordered'].append((page_no, col, top, left, p))\n",
    "\n",
    "    page['ordered'] = sorted(page['ordered'], key=lambda p: tuple(p[:4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4322ef70",
   "metadata": {},
   "source": [
    "## Stitch all of the text together into a single document\n",
    "\n",
    "We're just joining the pages here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e42f872",
   "metadata": {},
   "outputs": [],
   "source": [
    "SINGLE = []\n",
    "\n",
    "for page_no in sorted(PAGES.keys()):\n",
    "    page = PAGES[page_no]\n",
    "    SINGLE.extend([p for p in page['ordered']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f222f2",
   "metadata": {},
   "source": [
    "## Join lines\n",
    "\n",
    "This should put all of the lines back into a form similar to how they appear in the document.\n",
    "\n",
    "**Note: LINES will contain strings and not Beautiful Soup objects.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a36296ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "LINES = []\n",
    "\n",
    "prev = (0, 0, 0)\n",
    "line = []\n",
    "\n",
    "for p in SINGLE:\n",
    "    curr = (p[0], p[1], p[2])\n",
    "    if curr != prev and line:\n",
    "        LINES.append(''.join(line))\n",
    "        prev = curr\n",
    "        line = []\n",
    "    line.append(str(p[4]))\n",
    "\n",
    "# Handle any last remaining line fragments\n",
    "if line:\n",
    "    LINES.append(''.join(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74e96df",
   "metadata": {},
   "source": [
    "## Convert HTML entities into characters\n",
    "\n",
    "For reasons that make sense in a web setting, but not here, Beautiful Soup leaves some HTML entities unconverted. We don't want these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df7937e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "LINES = [ln.replace('&amp;', '&') for ln in LINES]\n",
    "LINES = [ln.replace('&lt;', '<') for ln in LINES]\n",
    "LINES = [ln.replace('&gt;', '>') for ln in LINES]\n",
    "LINES = [ln.replace('\\xa0', ' ') for ln in LINES]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b266bf8",
   "metadata": {},
   "source": [
    "## Remove the paragraph tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b64f0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "LINES = [ln.replace('<p>', '') for ln in LINES]\n",
    "LINES = [ln.replace('</p>', '') for ln in LINES]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda6b072",
   "metadata": {},
   "source": [
    "## Join lines that overflow in the document itself (Step 1)\n",
    "\n",
    "This will make parsing easier.\n",
    "\n",
    "So we want to turn something like:\n",
    "```\n",
    "*Macropus antilopinus (Gould) [Diprotodontia:\n",
    "Macropod.]\n",
    "```\n",
    "\n",
    "into this:\n",
    "```\n",
    "*Macropus antilopinus (Gould) [Diprotodontia: Macropod.]\n",
    "```\n",
    "\n",
    "It looks like we can use some heuristics for conservative line joining:\n",
    "- If the line starts with a `<b>` or a `<i>` tag then it's a line start.\n",
    "- If the line starts with an `*` then it's a line start.\n",
    "- If the line starts with a space then it's a line start.\n",
    "- Everything else is an \"overflow\" line and should be joined to the one above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19612cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "JOINED = []\n",
    "line = []\n",
    "\n",
    "starters = re.compile(r'^(<b>|<i>|\\*|\\s)')\n",
    "\n",
    "for ln in LINES:\n",
    "    if starters.match(ln) and line:\n",
    "        JOINED.append(' '.join(line))\n",
    "        line = []\n",
    "    line.append(ln)\n",
    "\n",
    "# Handle any last remaining line fragments\n",
    "if line:\n",
    "    JOINED.append(''.join(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73621eb",
   "metadata": {},
   "source": [
    "Some lines are broken in the middle of a `<i></i>` or `<b><i></i></b>`. Exceptions are, `nomen nudum` and `unknown`, so we'll park those texts before doing the mass text joins and restore them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9e7966e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = '\\n'.join(JOINED)\n",
    "\n",
    "# Park\n",
    "TEXT = TEXT.replace('<i>nomen nudum</i>', '|nomen nudum|')\n",
    "TEXT = TEXT.replace('<i>unknown</i>', '|unknown|')\n",
    "\n",
    "# Smerge lines\n",
    "TEXT = TEXT.replace('</i></b>\\n<b><i>', ' ')\n",
    "TEXT = re.sub(r'</i>\\n<i>(?!<)', ' ', TEXT)\n",
    "TEXT = TEXT.replace('</b> <b>', ' ')\n",
    "\n",
    "# Unpark\n",
    "TEXT = TEXT.replace('|unknown|', '<i>unknown</i>')\n",
    "TEXT = TEXT.replace('|nomen nudum|', '<i>nomen nudum</i>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d096c6a8",
   "metadata": {},
   "source": [
    "There are nested brackets in some references which will make regular expression parsing of the reference difficult. So I'll replace the interior square brackets `[]` with curly braces `{}`.\n",
    "\n",
    "For example:\n",
    "`[REF: Eichler [& Vasjukova], 1980:343]`\n",
    "will become\n",
    "`[REF: Eichler {& Vasjukova}, 1980:343]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c208364",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = re.sub(r'\\[& ( [^\\]]+ ) \\]', r'{&\\1}', TEXT, flags=FLAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36142712",
   "metadata": {},
   "outputs": [],
   "source": [
    "JOINED = TEXT.splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6dcb5984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('Price_louse_text.txt', 'w') as out_file:\n",
    "#     for p in JOINED:\n",
    "#         out_file.write(f'{p}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cdb6bd",
   "metadata": {},
   "source": [
    "## Join lines that overflow in the document itself (Step 2)\n",
    "\n",
    "The joining above did not link up all of the lines we needed. Step 1 was more about how lines started and this step is more about how lines end. There are situations where a line starts with a `<b>` or `<i>` and it is still a continuation line.\n",
    "\n",
    "### Look at the parity of parentheses. If a they're left open then join the line below. Ex:\n",
    "\n",
    "`\n",
    "<i><b>chloropodis</b></i> (Schrank, 1803:189) (subgenus\n",
    "<i>Eulaemobothrion</i>) [in <i>Pediculus</i>]\n",
    "`\n",
    "\n",
    "to:\n",
    "\n",
    "`\n",
    "<i><b>chloropodis</b></i> (Schrank, 1803:189) (subgenus <i>Eulaemobothrion</i>) [in <i>Pediculus</i>]\n",
    "`\n",
    "\n",
    "### We also have this equals sign `=` and `TYPE:` situation going on here. Ex:\n",
    "\n",
    "`\n",
    "<i>buteonis</i> (Fabricius [J.C.], 1777:309) [in <i>Pediculus</i>] =\n",
    "<i><b>maximum</b></i> [REF: Hopkins & Clay, 1952:183]\n",
    "`\n",
    "\n",
    "to:\n",
    "\n",
    "`\n",
    "<i>buteonis</i> (Fabricius [J.C.], 1777:309) [in <i>Pediculus</i>] = <i><b>maximum</b></i> [REF: Hopkins & Clay, 1952:183]\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9d9b3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dangling_paren(line):\n",
    "    opens = sum(1 for c in line if c in '([')\n",
    "    closes = sum(1 for c in line if c in ')]')\n",
    "    return opens > closes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18895cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "LINES = []\n",
    "\n",
    "LINE_ITER = iter(JOINED)\n",
    "\n",
    "for ln in LINE_ITER:\n",
    "\n",
    "    while dangling_paren(ln):\n",
    "        ln += ' ' + next(LINE_ITER)\n",
    "\n",
    "    while re.search(r'(=|TYPE:|of)$', ln):\n",
    "        ln += ' ' + next(LINE_ITER)\n",
    "\n",
    "    LINES.append(ln)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5d292a",
   "metadata": {},
   "source": [
    "## Fix specific lines\n",
    "\n",
    "There is broken data in the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0bab000b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<i>C. yolandae</i>\n"
     ]
    }
   ],
   "source": [
    "LINE_ITER = []\n",
    "for ln in LINES:\n",
    "\n",
    "    if ln.startswith('<i>C. yolandae</i>'):\n",
    "        ln = ln.replace('<i>C. yolandae</i>', '  <i>C. yolandae</i>')\n",
    "        print('<i>C. yolandae</i>')\n",
    "\n",
    "    LINE_ITER.append(ln)\n",
    "\n",
    "LINES = LINE_ITER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d272b38",
   "metadata": {},
   "source": [
    "## Clean up text for human readability\n",
    "\n",
    "Align type hosts with the rest of the hosts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6da2e879",
   "metadata": {},
   "outputs": [],
   "source": [
    "LINES = [f' {ln}' if ln[0] == '*' else ln for ln in LINES]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8156cd",
   "metadata": {},
   "source": [
    "## Examine results so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31554240",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_DIR / 'Price_louse_text.txt', 'w') as out_file:\n",
    "    for p in LINES:\n",
    "        out_file.write(f'{p}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08f218f",
   "metadata": {},
   "source": [
    "## Finally, we can start parsing\n",
    "\n",
    "Quoting from the paper:\n",
    "\n",
    "- Checklist is ordered alphabetically by chewing louse family, genus, species, and subspecies.\n",
    "- Valid generic and specific names appear in bold face.\n",
    "- Taxonomic names are followed by the author, year of publication, and the beginning page number of the description.\n",
    "- Author names are not abbreviated except for Linnaeus (=L.), Blagoveshtchensky (=Blagov.), Burmeister (=Burm.), and Timmermann (=Timmer.).\n",
    "- Generic name listings include the type species.\n",
    "- Where the genus name has changed from the original description, “in” followed by the original genus name appears in brackets.\n",
    "- Junior synonyms appear in plain face type followed by an “=” and, in bold face, the name of the taxon that we regard as valid. This is followed by the citation for the synonomy. Where no reference is given, we believe the synonomy to be new.\n",
    "- Associated hosts appear in alphabetical order indented below each louse taxon, with the name of the type host preceded by an asterisk.\n",
    "- Host names are followed by the author, order and family and, for other than the type host, by a citation documenting the host-louse association.\n",
    "- We have not attempted to cite the first publication documenting the association, instead favoring sources that we regard as most reliable.\n",
    "- Where no source is given, the association is attributable to the authors of the checklist.\n",
    "- Bird orders are abbreviated by the omission of “iformes,” and host family names are abbreviated by the omission of “idae.”\n",
    "- Where “? Host” appears, we believe that the name of type host indicated by the author of the louse taxon cannot be assigned to valid host species.\n",
    "- Where “? ID” appears, we believe that, while the name is valid, the host probably was misidentified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ee3b86",
   "metadata": {},
   "source": [
    "### Regular expressions for parsing lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7542fe79",
   "metadata": {},
   "source": [
    "#### Louse family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75ccbe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "louse_family = re.compile(r\"\"\"<b> (?P<family> [A-Z]+ ) </b> $\"\"\", flags=FLAGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78678c6",
   "metadata": {},
   "source": [
    "#### Louse genus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43934fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "louse_genus = re.compile(r\"\"\"\n",
    "    <i><b>       (?P<genus>      [A-Z][a-z]+)  </b></i> \\s*\n",
    "                 (?P<genus_ref>  .+ (?! TYPE:) )   \\s*\n",
    "    TYPE: \\s <i> (?P<genus_type> [A-Za-z\\s]+ ) </i>\n",
    "    \\s*           (?P<genus_type_ref> .* )?\n",
    "    $ \"\"\", flags=FLAGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cc942d",
   "metadata": {},
   "source": [
    "#### Louse genus synonym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17cd7da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "louse_genus_syn = re.compile(r\"\"\"\n",
    "    <i>            (?P<genus_syn>      [A-Z][a-z.]+ )          </i> \\s*\n",
    "                   (?P<genus_type_ref> [^=]+ )                      \\s*\n",
    "    = \\s* <i><b>   (?P<genus>          [^<]+ )             </b></i> \\s*\n",
    "    (?: \\s* \\[     (?P<genus_new_syn>  New \\s Syn) \\.            \\] \\s* )?\n",
    "    (?: \\[REF: \\s* (?P<genus_syn_ref>  [^\\]]+ )                  \\] \\s* )?\n",
    "    TYPE: \\s* <i>  (?P<genus_type>     [A-Za-z\\s]+ )           </i> \\s*\n",
    "    \\s*            (?P<skip> .* )?\n",
    "    $ \"\"\", flags=FLAGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3c9437",
   "metadata": {},
   "source": [
    "#### Louse subgenus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b05a043",
   "metadata": {},
   "outputs": [],
   "source": [
    "louse_subgenus = re.compile(r\"\"\"\n",
    "    <i>            (?P<subgenus>      [A-Z][a-z.]+ ) </i>     \\s*\n",
    "                   (?P<subgenus_ref>  [^=]+ )                 \\s*\n",
    "    = \\s* subgenus \\s of \\s*\n",
    "    <i><b>         (?P<genus>         [A-Z][a-z.]+ ) </b></i> \\s*\n",
    "    (?: \\[REF: \\s* (?P<genus_ref>     [^\\]]+ )       \\]       \\s* )?\n",
    "    (?: \\s* \\[     (?P<genus_new_syn> New \\s Syn) \\. \\]       \\s* )?\n",
    "    TYPE: \\s* <i>  (?P<subgenus_type> [A-Za-z\\s]+ )  </i>     \\s*\n",
    "    \\s*            (?P<subgenus_type_ref> .+ )?\n",
    "    $ \"\"\", flags=FLAGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ca770f",
   "metadata": {},
   "source": [
    "#### Louse species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "00034dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "louse_species = re.compile(r\"\"\"\n",
    "    <i><b>           (?P<species>     [a-z.]+ )    </b></i>    \\s*\n",
    "                     (?P<species_ref> [^\\(\\[]+ )               \\s*\n",
    "    (?: \\( subgenus \\s <i> (?P<subgenus> [A-Z][a-z.]+) </i> \\) \\s* )?\n",
    "    (?: \\[ in \\s <i> (?P<genus_ori>   [^<]+ )          </i> \\] \\s* )?\n",
    "    $ \"\"\", flags=FLAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38bffa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "louse_species2 = re.compile(r\"\"\"\n",
    "    <i><b>           (?P<species>      [a-z.]+ )      </b></i> \\s*\n",
    "        \\(           (?P<species_ref>  [^\\)]+ )             \\) \\s*\n",
    "    (?: \\( subgenus \\s <i> (?P<subgenus> [A-Z][a-z.]+) </i> \\) \\s* )?\n",
    "    (?: \\[ in \\s <i> (?P<genus_ori>    [A-Z][a-z.]+ )  </i> \\] \\s* )?\n",
    "    $ \"\"\", flags=FLAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4c72a752",
   "metadata": {},
   "outputs": [],
   "source": [
    "louse_species3 = re.compile(r\"\"\"\n",
    "    <i><b>           (?P<species>     [a-z.]+ )    </b></i>    \\s*\n",
    "    (?P<species_ref> [^\\[]+ \\[ [^\\]]+ \\] [^\\(\\[]+ )            \\s*\n",
    "    (?: \\( subgenus \\s <i> (?P<subgenus> [A-Z][a-z.]+) </i> \\) \\s* )?\n",
    "    (?: \\[ in \\s <i> (?P<genus_ori>   [^<]+ )          </i> \\] \\s* )?\n",
    "    $ \"\"\", flags=FLAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "adc8c375",
   "metadata": {},
   "outputs": [],
   "source": [
    "louse_species4 = re.compile(r\"\"\"\n",
    "    <i><b> (?P<species>     [a-z.]+ )        </b></i>  \\s*\n",
    "    (?: nomen \\s novum \\s* )?\n",
    "    (?: \\[ in \\s <i> (?P<genus_ori>   [^<]+  ) </i> \\] \\s* )?\n",
    "    (?: \\[ (?P<species_ref> [^\\]]+ ) \\] | \\( (?P<species_ref2> [^\\)]+ ) \\) ) \\s*\n",
    "    $ \"\"\", flags=FLAGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe8259f",
   "metadata": {},
   "source": [
    "#### Louse species synonym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "159517ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "louse_species_syn = re.compile(r\"\"\"\n",
    "    <i> (?P<species_syn> (([A-Z][.] | [A-Z][a-z]+)  \\s )? [a-z]+ )  </i> \\s*\n",
    "                     (?P<species_syn_ref> [^\\[=]+ ) \\s*\n",
    "    (?: \\[ in \\s <i> (?P<genus_ori>       [^\\[<]+ ) </i> \\]  \\s* )?\n",
    "    (?: = \\s* <i><b> (?P<species>         [^<]+   ) </b></i> \\s* )\n",
    "    (?: \\[           (?P<new_syn> New \\s Syn\\. )         \\]  \\s* )?\n",
    "    (?: \\[(?: REF: )? \\s* (?P<species_ref>  .+ )         \\]      )?\n",
    "    $\"\"\", flags=FLAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1941e5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "louse_species_syn2 = re.compile(r\"\"\"\n",
    "    <i> (?P<species_syn> (([A-Z][.] | [A-Z][a-z]+)  \\s )? [a-z]+ )  </i> \\s*\n",
    "    \\(? (?P<species_ref> [^\\[]+ \\[ [^\\]]+ \\] [^\\(\\[]+ )         \\)?  \\s*\n",
    "    (?: \\[ in \\s <i> (?P<genus_ori>       [^<]+   ) </i> \\]  \\s* )?\n",
    "    (?: = \\s* <i><b> (?P<species>         [^<]+ )   </b></i> \\s* )\n",
    "    (?: \\[(?: REF: )? \\s* (?P<species_syn_ref>  [^\\]]+ )     \\]      )?\n",
    "    $\"\"\", flags=FLAGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ddf91f",
   "metadata": {},
   "source": [
    "#### Louse subspecies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "03a3868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "louse_subspecies = re.compile(r\"\"\"\n",
    "    <i><b>           (?P<subspecies> [a-z.]+ \\s [a-z.]+ ) </b></i> \\s*\n",
    "                     (?P<subspecies_ref> [^\\(\\[]+ )            \\s*\n",
    "    (?: \\( subgenus \\s <i> (?P<subgenus> [A-Z][a-z.]+) </i> \\) \\s* )?\n",
    "    (?: \\[ in \\s <i> (?P<genus_ori>   [^<]+ )          </i> \\] \\s* )?\n",
    "    $ \"\"\", flags=FLAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "073052d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "louse_subspecies2 = re.compile(r\"\"\"\n",
    "    <i><b>           (?P<subspecies> [a-z.]+ \\s [a-z.]+ ) </b></i> \\s*\n",
    "        \\(           (?P<subspecies_ref>  [^\\)]+ )          \\) \\s*\n",
    "    (?: \\( subgenus \\s <i> (?P<subgenus> [A-Z][a-z.]+) </i> \\) \\s* )?\n",
    "    (?: \\[ in \\s <i> (?P<genus_ori>    [A-Z][a-z.]+ )  </i> \\] \\s* )?\n",
    "    $ \"\"\", flags=FLAGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd11dfd",
   "metadata": {},
   "source": [
    "#### Louse subspecies synonym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6239108f",
   "metadata": {},
   "outputs": [],
   "source": [
    "louse_subspecies_syn = re.compile(r\"\"\"\n",
    "    <i> (?P<subspecies_syn> [a-z.]+ \\s [a-z.]+ )    </i> \\s*\n",
    "                     (?P<subspecies_syn_ref> [^\\(\\[=]+ ) \\s*\n",
    "    (?: \\[ in \\s <i> (?P<genus_ori>       [^\\[<]+ ) </i> \\]  \\s* )?\n",
    "    (?: = \\s* <i><b> (?P<species>         [^<]+   ) </b></i> \\s* )?\n",
    "    (?: \\[           (?P<new_syn> New \\s Syn\\. )         \\]  \\s* )?\n",
    "    (?: \\[(?: REF: )? \\s* (?P<species_ref>  .+ )         \\]      )?\n",
    "    $\"\"\", flags=FLAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a926c8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "louse_subspecies_syn2 = re.compile(r\"\"\"\n",
    "    <i> (?P<subspecies_syn> [a-z.]+ \\s [a-z.]+ )  </i> \\s*\n",
    "    \\(  (?P<subspecies_syn_ref> [^)]+          )  \\)   \\s*\n",
    "    (?: \\[ in \\s <i> (?P<genus_ori>       [^<]+   ) </i> \\]        \\s* )?\n",
    "    (?: = \\s* <i><b> (?P<species>         [^<]+ )   </b></i>       \\s* )?\n",
    "    (?: \\[(?: REF: )? \\s* (?P<species_ref>  [^\\]]+ )     \\]            )?\n",
    "    $\"\"\", flags=FLAGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79032dc7",
   "metadata": {},
   "source": [
    "#### Host species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0ea8a4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lines = [ln for ln in LINES if re.match(r'\\s', ln)]\n",
    "# lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b7859981",
   "metadata": {},
   "outputs": [],
   "source": [
    "host_species = re.compile(r\"\"\"\n",
    "    \\s+     (?P<type_host>     \\*)?  \n",
    "        <i> (?P<host_species> [^<]+ )                                 </i>  \\s*\n",
    "    (?:     (?P<invalid_host> \\? \\s (host | ID) )                           \\s* )?\n",
    "    (?: \\(? (?P<host_auth>    [^\\[]+    )                               \\)? \\s* )?\n",
    "    (?: \\[  (?P<host_order>   [\\w.]+ ) :? \\s+ (?P<host_family> \\w+ \\.? ) \\] \\s* )?\n",
    "    (?: \\[REF: \\s* (?P<host_ref> [^\\]]+ )                             \\]    \\s* )?\n",
    "    $ \"\"\", flags=FLAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "858ff2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ln in lines:\n",
    "#     if not (host_species.match(ln)):\n",
    "#         print(ln)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25e4a16",
   "metadata": {},
   "source": [
    "### Parse the lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e84c4457",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hosts = []\n",
    "generic = []\n",
    "specific = []\n",
    "\n",
    "family = {}\n",
    "genus = {}\n",
    "species = {}\n",
    "\n",
    "for ln in LINES:\n",
    "\n",
    "    if match := louse_family.match(ln):\n",
    "        family = {\n",
    "            'family': match.group('family'),\n",
    "        }\n",
    "\n",
    "    elif match := louse_genus.match(ln):\n",
    "        genus = {\n",
    "            'generic': match.group('genus'),\n",
    "            'genus': match.group('genus'),\n",
    "            'genus_ref': match.group('genus_ref'),\n",
    "            'genus_type': match.group('genus_type'),\n",
    "            'genus_type_ref': match.group('genus_type_ref'),\n",
    "        }\n",
    "        generic.append(genus)\n",
    "\n",
    "    elif match := louse_genus_syn.match(ln):\n",
    "        genus = {\n",
    "            'generic': match.group('genus'),\n",
    "            'genus': match.group('genus'),\n",
    "            'genus_ref': '',  # match.group('genus_ref'),\n",
    "            'genus_type': match.group('genus_type'),\n",
    "            'genus_type_ref': match.group('genus_type_ref'),\n",
    "            'genus_syn': match.group('genus_syn'),\n",
    "            'genus_syn_ref': match.group('genus_syn_ref'),\n",
    "            'genus_new_syn': match.group('genus_new_syn'),\n",
    "        }\n",
    "        generic.append(genus)\n",
    "\n",
    "    elif match := louse_subgenus.match(ln):\n",
    "        genus = {\n",
    "            'generic': match.group('subgenus'),\n",
    "            'subgenus': match.group('subgenus'),\n",
    "            'subgenus_ref': match.group('subgenus_ref'),\n",
    "            'genus': match.group('genus'),\n",
    "            'genus_ref': match.group('genus_ref'),\n",
    "            'subgenus_type': match.group('subgenus_type'),\n",
    "            'subgenus_type_ref': match.group('subgenus_type_ref'),\n",
    "            'genus_new_syn': match.group('genus_new_syn'),\n",
    "        }\n",
    "        generic.append(genus)\n",
    "\n",
    "    elif match := louse_species.match(ln):\n",
    "        species = {\n",
    "            'specific': match.group('species'),\n",
    "            'species': match.group('species'),\n",
    "            'species_ref': match.group('species_ref'),\n",
    "            'genus_ori': match.group('genus_ori'),\n",
    "            'subgenus': match.group('subgenus'),\n",
    "        }\n",
    "        specific.append(species)\n",
    "\n",
    "    elif match := louse_species2.match(ln):\n",
    "        species = {\n",
    "            'specific': match.group('species'),\n",
    "            'species': match.group('species'),\n",
    "            'species_ref': match.group('species_ref'),\n",
    "            'genus_ori': match.group('genus_ori'),\n",
    "            'subgenus': match.group('subgenus'),\n",
    "        }\n",
    "        specific.append(species)\n",
    "\n",
    "    elif match := louse_species3.match(ln):\n",
    "        species = {\n",
    "            'specific': match.group('species'),\n",
    "            'species': match.group('species'),\n",
    "            'species_ref': match.group('species_ref'),\n",
    "            'genus_ori': match.group('genus_ori'),\n",
    "            'subgenus': match.group('subgenus'),\n",
    "        }\n",
    "        specific.append(species)\n",
    "\n",
    "    elif match := louse_species4.match(ln):\n",
    "        species = {\n",
    "            'specific': match.group('species'),\n",
    "            'species': match.group('species'),\n",
    "            'species_ref': match.group('species_ref'),\n",
    "            'genus_ori': match.group('genus_ori'),\n",
    "        }\n",
    "        specific.append(species)\n",
    "\n",
    "    elif match := louse_species_syn.match(ln):\n",
    "        species = {\n",
    "            'specific': match.group('species_syn'),\n",
    "            'species': match.group('species'),\n",
    "            'species_ref': '',  # match.group('species_ref'),\n",
    "            'species_syn': match.group('species_syn'),\n",
    "            'species_syn_ref': match.group('species_ref'),\n",
    "            'genus_ori': match.group('genus_ori'),\n",
    "        }\n",
    "        specific.append(species)\n",
    "\n",
    "    elif match := louse_species_syn2.match(ln):\n",
    "        species = {\n",
    "            'specific': match.group('species_syn'),\n",
    "            'species': match.group('species'),\n",
    "            'species_ref': '',  # match.group('species_ref'),\n",
    "            'species_syn': match.group('species_syn'),\n",
    "            'species_syn_ref': match.group('species_ref'),\n",
    "            'genus_ori': match.group('genus_ori'),\n",
    "        }\n",
    "        specific.append(species)\n",
    "\n",
    "    elif match := louse_subspecies.match(ln):\n",
    "        species = {\n",
    "            'specific': match.group('subspecies'),\n",
    "            'subspecies': match.group('subspecies'),\n",
    "            'subspecies_ref': match.group('subspecies_ref'),\n",
    "            'genus_ori': match.group('genus_ori'),\n",
    "            'subgenus': match.group('subgenus'),\n",
    "        }\n",
    "        specific.append(species)\n",
    "        \n",
    "    elif match := louse_subspecies2.match(ln):\n",
    "        species = {\n",
    "            'specific': match.group('subspecies'),\n",
    "            'subspecies': match.group('subspecies'),\n",
    "            'subspecies_ref': match.group('subspecies_ref'),\n",
    "            'genus_ori': match.group('genus_ori'),\n",
    "            'subgenus': match.group('subgenus'),\n",
    "        }\n",
    "        specific.append(species)\n",
    "\n",
    "    elif match := louse_subspecies_syn.match(ln):\n",
    "        species = {\n",
    "            'specific': match.group('subspecies_syn'),\n",
    "            'subspecies_syn': match.group('subspecies_syn'),\n",
    "            'subspecies_syn_ref': match.group('subspecies_syn_ref'),\n",
    "            'genus_ori': match.group('genus_ori'),\n",
    "            'species': match.group('species'),\n",
    "            'species_ref': '',  # match.group('species_ref'),\n",
    "        }\n",
    "        specific.append(species)\n",
    "\n",
    "    elif match := louse_subspecies_syn2.match(ln):\n",
    "        species = {\n",
    "            'specific': match.group('subspecies_syn'),\n",
    "            'subspecies_syn': match.group('subspecies_syn'),\n",
    "            'subspecies_syn_ref': match.group('subspecies_syn_ref'),\n",
    "            'genus_ori': match.group('genus_ori'),\n",
    "            'species': match.group('species'),\n",
    "            'species_ref': '',  # match.group('species_ref'),\n",
    "        }\n",
    "        specific.append(species)\n",
    "\n",
    "    elif match := host_species.match(ln):\n",
    "        host = {\n",
    "            'type_host': match.group('type_host'),\n",
    "            'host_species': match.group('host_species'),\n",
    "            'host_auth': match.group('host_auth'),\n",
    "            'host_order': match.group('host_order'),\n",
    "            'host_family': match.group('host_family'),\n",
    "            'invalid_host': match.group('invalid_host'),\n",
    "            'host_ref': match.group('host_ref'),\n",
    "        }\n",
    "        row = host | family | genus | species\n",
    "        hosts.append(row)\n",
    "\n",
    "    # Print lines that do not match a pattern\n",
    "    else:\n",
    "        print(ln)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b78d7e",
   "metadata": {},
   "source": [
    "## Output results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2ca4b007",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce7f3642",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {\n",
    "    'hosts': hosts,\n",
    "    'generic': generic,\n",
    "    'specific': specific,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2d4e81c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT = Path('.') / 'output'\n",
    "\n",
    "for name, lst in dfs.items():\n",
    "    df = pd.DataFrame(lst)\n",
    "    path = OUTPUT / f'{name}.csv'\n",
    "    df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0639a1a",
   "metadata": {},
   "source": [
    "# Hmm...\n",
    "\n",
    "### In retrospect the regular expressions were not a good idea at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f43266b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
